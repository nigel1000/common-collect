# Raft 算法
Raft 算法是一种简单易懂的共识算法。它依靠 **状态机** 和 **主从同步** 的方式，在各个节点之间实现数据的一致性。 

## 状态机
Raft算法为节点定义了三种角色：  
1. Leader（主节点）
2. Follower（从节点）
3. Candidate（参与投票竞争的节点）  

## 主从同步
使用主从同步的方式，可以让集群各个节点的数据更新以主节点为准，从而保证了一致性。  
主从同步的两个核心要点：
1. 选取主节点  
2. 同步数据 

### 选取主节点  
Raft算法在选择主节点的过程中，通过多个节点之间的投票竞争。  
具体流程：
1. 在最初，还没有一个主节点的时候，所有节点的身份都是Follower。每一个节点都有自己的计时器，当计时达到了超时时间（Election Timeout），该节点会转变为Candidate。  
2. 成为Candidate的节点，会首先给自己投票，然后向集群中其他所有的节点发起请求，要求大家都给自己投票。
3. 当得票数超过了集群节点数量的一半，该节点晋升为Leader节点。Leader节点会立刻向其他节点发出通知，告诉大家自己是 Leader。收到通知的节点全部变为Follower，并且各自的计时器清零。  

Leader节点需要每隔一段时间向集群其他节点发送心跳通知，表明 Leader 还活着。
一旦Leader节点挂掉，发不出心跳通知，那么计时达到了超时时间的Follower节点会转变为Candidate节点，再次发起选主投票。
```
ps：每个节点的超时时间都是不一样的。比如A节点的超时时间是3秒，B节点的超时时间是5秒，C节点的超时时间是4秒。这样一来，A节点将会最先发起投票请求，而不是所有节点同时发起。
设想如果所有节点同时发起投票，必然会导致大家的票数差不多，形成僵局，谁也当不成 Leader。
```

### 同步数据 
数据同步的流程：  
1. 由客户端提交数据到Leader节点。
2. 由Leader节点把数据复制到集群内所有的Follower节点。如果一次复制失败，会不断进行重试。
3. Follower节点们接收到复制的数据，会 ack 给Leader节点。
4. 如果 Leader 节点接收到超过半数的Follower反馈，表明复制成功。于是提交自己的数据，并通知客户端数据提交成功。
5. 由Leader节点通知集群内所有的Follower节点提交数据，从而完成数据同步流程。


# Gossip 协议

Gossip 过程是由种子节点发起，当一个种子节点有状态需要更新到网络中的其他节点时，它会随机的选择周围几个节点散播消息，收到消息的节点也会重复该过程，直至最终网络中所有的节点都收到了消息。  
这个过程可能需要一定的时间，由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个最终一致性协议。  
可以设定一些扩散规则：
- Gossip 是周期性的散播消息，把周期限定为 1 秒
- 被感染节点随机选择 k 个邻接节点（fan-out）散播消息，这里把 fan-out 设置为 3，每次最多往 3 个节点散播。
- 每次散播消息都选择尚未发送过的节点进行散播
- 收到消息的节点不再往发送节点散播，比如 A -> B，那么 B 进行散播的时候，不再发给 A。

## Gossip 的类型：
- Anti-Entropy（反熵）：以固定的概率传播所有的数据  
- Rumor-Mongering（谣言传播）：仅传播新到达的数据  

Anti-Entropy 是 SI model，节点只有两种状态，Suspective 和 Infective，叫做 simple epidemics。  
Rumor-Mongering 是 SIR model，节点有三种状态，Suspective，Infective 和 Removed，叫做 complex epidemics。  

在 SI model 下，一个节点会把所有的数据都跟其他节点共享，以便消除节点之间数据的任何不一致，它可以保证最终、完全的一致。
由于在 SI model 下消息会不断反复的交换，因此消息数量是非常庞大的，无限制的（unbounded），这对一个系统来说是一个巨大的开销。 
 
在 SIR Model 下，消息可能发送得更频繁，因为消息只包含最新 update，体积更小。一个 Rumor 消息在某个时间点之后会被标记为 removed，并且不再被传播，因此系统有一定的概率会不一致。
SIR Model 下某个时间点之后消息不再传播，因此消息是有限的，系统开销小。

## Gossip 的通信模式
在 Gossip 协议下，网络中两个节点之间有三种通信方式:  
- Push: 节点 A 将数据 (key,value,version) 及对应的版本号推送给 B 节点，B 节点更新 A 中比自己新的数据  
- Pull：A 仅将数据 key, version 推送给 B，B 将本地比 A 新的数据（Key, value, version）推送给 A，A 更新本地  
- Push/Pull：与 Pull 类似，只是多了一步，A 再将本地比 B 新的数据推送给 B，B 则更新本地  

如果把两个节点数据同步一次定义为一个周期，则在一个周期内，Push 需通信 1 次，Pull 需 2 次，Push/Pull 则需 3 次。  
虽然消息数增加了，但从效果上来讲，Push/Pull 最好，理论上一个周期内可以使两个节点完全一致。直观上，Push/Pull 的收敛速度也是最快的。  

## Gossip 的优势
- 扩展性，网络可以允许节点的任意增加和减少，新增加的节点的状态最终会与其他节点一致。
- 容错，网络中任何节点的宕机和重启都不会影响 Gossip 消息的传播，Gossip 协议具有天然的分布式系统容错特性。
- 去中心化，Gossip 协议不要求任何中心节点，所有节点都可以是对等的，任何一个节点无需知道整个网络状况，只要网络是连通的，任意一个节点就可以把消息散播到全网。
- 一致性收敛，Gossip 协议中的消息会以一传十、十传百一样的指数级速度在网络中快速传播，因此系统状态的不一致可以在很快的时间内收敛到一致。消息传播速度达到了 logN。
- 简单，Gossip 协议的过程极其简单，实现起来几乎没有太多复杂性。

## Gossip 的缺陷
分布式网络中，没有一种完美的解决方案，Gossip 协议跟其他协议一样，也有一些不可避免的缺陷。  
主要是两个：
- 消息的延迟  
由于 Gossip 协议中，节点只会随机向少数几个节点发送消息，消息最终是通过多个轮次的散播而到达全网的，因此使用 Gossip 协议会造成不可避免的消息延迟。不适合用在对实时性要求较高的场景下。
- 消息冗余  
Gossip 协议规定，节点会定期随机选择周围节点发送消息，而收到消息的节点也会重复该步骤，因此就不可避免的存在消息重复发送给同一节点的情况，造成了消息的冗余，同时也增加了收到消息的节点的处理压力。  
由于是定期发送而且不反馈，因此，即使节点收到了消息，还是会反复收到重复消息，加重了消息的冗余。

# Paxos
| Phase(阶段) | Proposers(提案者) | Acceptors(投票者) |
|:---|:---|:---|
|第一阶段投票提案|生成一个提案序号 n | |
|第一阶段投票提案|广播 Prepare(n) 给所有的 acceptors | |
|第一阶段投票提案| |回复 Prepare(n) <br> 1.if n 大于 minProposal then minProposal = n <br> 2. 回复(acceptedProposal,acceptedValue)|
|第一阶段投票提案|收到多数派的回复信息：<br> 如果 acceptedValue 不为空，将自己的 value 替换成 acceptedProposal 序号最大的 acceptedValue 值| |
|第二阶段确认提案|广播 Accept(n,value) 给所有的 acceptor| |
|第二阶段确认提案| |回复 Accept(n,value) <br> if n >= minProposal then acceptedProposal = minProposal = n, acceptedValue = value,回复(minProposal)|
|第二阶段确认提案|收到多数派的回复信息：<br> 拒绝信息(result>n)的话，重新第1步，否则，value 被 acceptor 确认||

